{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libs\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installed using cmd for current venv\n",
    "#python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = \"D:/_workspace/vscode_workspace/Universit√§t-Trier/NLP/source_txt_files_ClimateChange/2022-11-25_386.txt - 2022-12-29_428.txt/2022-12-29_428.txt\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content from the file\n",
    "with open(source_file, \"r\") as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring Conell-2003 data file(Source: https://www.clips.uantwerpen.be/conll2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of Word_A and Word_B Combinations:\n",
      "NN I-NP(2338500)\n",
      "NNP I-NP(2132412)\n",
      "IN I-PP(1536758)\n",
      "DT I-NP(1223799)\n",
      "CD I-NP(1077284)\n",
      "NNS I-NP(983854)\n",
      "JJ I-NP(933914)\n",
      "VBD I-VP(679521)\n",
      ". O(653936)\n",
      ", O(597461)\n",
      "VB I-VP(418092)\n",
      "VBN I-VP(304341)\n",
      "VBZ I-VP(246893)\n",
      "CC O(240260)\n",
      "\" O(231487)\n",
      "PRP I-NP(226643)\n",
      "TO I-VP(220679)\n",
      "VBG I-VP(195842)\n",
      "RB I-ADVP(191191)\n",
      "MD I-VP(147324)\n",
      "VBP I-VP(144214)\n",
      ": O(132474)\n",
      "IN I-SBAR(129441)\n",
      "TO I-PP(129163)\n",
      "POS B-NP(124031)\n",
      "PRP$ I-NP(113147)\n",
      "JJ I-ADJP(111923)\n",
      ") O(96887)\n",
      "RB I-VP(96688)\n",
      "( O(94361)\n",
      "CC I-NP(93836)\n",
      "SYM O(86401)\n",
      "$ I-NP(76565)\n",
      "-X- O(60343)\n",
      "NNPS I-NP(49746)\n",
      "RB I-NP(46467)\n",
      "DT B-NP(44744)\n",
      "RP I-PRT(39009)\n",
      "JJR I-NP(38732)\n",
      ": I-NP(36844)\n",
      "VBG I-NP(30761)\n",
      "IN I-NP(30138)\n",
      "WDT I-NP(30135)\n",
      "PRP B-NP(27967)\n",
      "VBN I-NP(27404)\n",
      "WDT B-NP(27208)\n",
      "JJS I-NP(26369)\n",
      "RB I-ADJP(25901)\n",
      "WRB I-ADVP(23443)\n",
      "NNP B-NP(23299)\n",
      "CD B-NP(23154)\n",
      ", I-NP(22004)\n",
      "NNP O(19476)\n",
      "WP I-NP(17710)\n",
      "IN B-PP(16357)\n",
      "EX I-NP(15809)\n",
      "JJ B-NP(15437)\n",
      "VBG I-PP(14673)\n",
      "RB O(12403)\n",
      "JJR I-ADJP(10077)\n",
      "WP B-NP(9543)\n",
      "TO B-PP(9093)\n",
      "CD O(8857)\n",
      "RBR I-ADVP(8707)\n",
      "POS I-NP(7739)\n",
      "TO I-NP(7367)\n",
      "RB I-CONJP(7272)\n",
      "NN B-NP(7147)\n",
      "VBN I-PP(6458)\n",
      "TO B-VP(6086)\n",
      "CC I-VP(6027)\n",
      "IN I-ADVP(5949)\n",
      "FW I-NP(5756)\n",
      "VBN I-ADJP(5598)\n",
      "RBR I-NP(4861)\n",
      "RBR I-ADJP(4813)\n",
      "IN B-NP(4504)\n",
      ". I-NP(4125)\n",
      "$ B-NP(3870)\n",
      "JJ I-PP(3729)\n",
      "JJ I-ADVP(3696)\n",
      "SYM I-VP(3465)\n",
      "RBS I-NP(3370)\n",
      "RB I-PP(3355)\n",
      "IN I-CONJP(3291)\n",
      "NN I-VP(3209)\n",
      "PRP$ B-NP(2851)\n",
      "CC I-ADJP(2760)\n",
      "UH I-INTJ(2666)\n",
      "CD I-ADVP(2582)\n",
      "PDT I-NP(2552)\n",
      "NN I-ADVP(2469)\n",
      "NNS B-NP(2445)\n",
      "NN O(2432)\n",
      "VBZ B-VP(2278)\n",
      "DT O(2202)\n",
      "VBD B-VP(2202)\n",
      "'' O(1984)\n",
      "JJR I-ADVP(1886)\n",
      "RB B-NP(1731)\n",
      "MD B-VP(1697)\n",
      "VB I-NP(1588)\n",
      "WP$ I-NP(1564)\n",
      "RB B-ADVP(1551)\n",
      "JJ I-VP(1498)\n",
      "JJ O(1441)\n",
      "IN O(1419)\n",
      "( I-LST(1402)\n",
      "RB I-SBAR(1352)\n",
      "( I-NP(1283)\n",
      "RBR B-NP(1213)\n",
      "JJS I-ADJP(1115)\n",
      "LS I-LST(1093)\n",
      ") I-NP(1071)\n",
      "VBZ I-NP(1066)\n",
      "NN I-ADJP(1064)\n",
      "DT I-SBAR(1057)\n",
      "IN B-SBAR(1044)\n",
      "IN I-VP(1043)\n",
      "NNS I-VP(1032)\n",
      "VBP B-VP(1031)\n",
      "RBR I-VP(1002)\n",
      "DT I-ADVP(979)\n",
      "RBS I-ADJP(955)\n",
      "'' I-NP(900)\n",
      "RP I-ADVP(897)\n",
      "MD O(892)\n",
      "EX B-NP(874)\n",
      "JJS I-ADVP(790)\n",
      "CC I-ADVP(785)\n",
      "NNP I-VP(783)\n",
      "WP$ B-NP(735)\n",
      "CC I-PP(727)\n",
      "JJR B-NP(696)\n",
      "$ I-ADJP(691)\n",
      ", I-VP(685)\n",
      "VBZ O(641)\n",
      "IN I-ADJP(629)\n",
      "CC I-CONJP(617)\n",
      "RB I-PRT(612)\n",
      "WRB I-NP(608)\n",
      "WRB B-ADVP(594)\n",
      "RP I-PP(562)\n",
      "SYM I-NP(535)\n",
      "VBD O(518)\n",
      "VBP O(499)\n",
      "FW O(451)\n",
      ": I-INTJ(442)\n",
      "CD I-ADJP(441)\n",
      ", B-NP(401)\n",
      "RBS I-ADVP(391)\n",
      "SYM B-NP(390)\n",
      "RB I-INTJ(387)\n",
      "VBG I-ADJP(379)\n",
      "CC B-NP(377)\n",
      "VBG B-VP(369)\n",
      "IN I-PRT(368)\n",
      "VBD I-NP(356)\n",
      "VB I-INTJ(351)\n",
      "PRP O(326)\n",
      "DT I-ADJP(280)\n",
      "CD I-VP(274)\n",
      "NN|SYM B-NP(254)\n",
      "NNP I-ADJP(253)\n",
      ", I-ADJP(253)\n",
      "VBN B-VP(250)\n",
      "WRB I-ADJP(238)\n",
      "NN I-INTJ(232)\n",
      ": I-ADVP(226)\n",
      ", B-VP(219)\n",
      "NNS O(212)\n",
      "TO O(198)\n",
      "RBS I-VP(196)\n",
      "VB O(171)\n",
      "PDT B-NP(159)\n",
      "JJR O(155)\n",
      "VB B-VP(146)\n",
      "POS I-VP(143)\n",
      "VBN O(139)\n",
      "RP O(126)\n",
      "PDT O(123)\n",
      "DT I-VP(122)\n",
      "JJS B-NP(121)\n",
      "FW I-ADVP(113)\n",
      "RBR I-PP(109)\n",
      "NNS I-ADJP(100)\n",
      "TO I-ADJP(100)\n",
      "JJS I-VP(99)\n",
      "NN|SYM I-NP(95)\n",
      "DT I-PP(92)\n",
      "NNS I-ADVP(90)\n",
      "IN B-ADVP(86)\n",
      "VBP I-NP(82)\n",
      "NNP I-INTJ(82)\n",
      ", I-PP(78)\n",
      "NN I-UCP(77)\n",
      "TO I-ADVP(76)\n",
      "NNPS B-NP(69)\n",
      "RB B-SBAR(65)\n",
      "FW I-PP(63)\n",
      "CC I-UCP(62)\n",
      "VBN B-NP(62)\n",
      "VBD B-NP(61)\n",
      "JJ I-UCP(60)\n",
      "# I-NP(60)\n",
      "NNP B-VP(59)\n",
      "RP I-NP(58)\n",
      "JJ I-INTJ(57)\n",
      "JJ B-ADJP(53)\n",
      "UH I-NP(51)\n",
      "NNP I-ADVP(51)\n",
      "WRB O(45)\n",
      "POS I-INTJ(45)\n",
      "PRP$ O(44)\n",
      "FW I-INTJ(42)\n",
      "VBN B-PP(40)\n",
      "UH I-ADVP(39)\n",
      "'' I-INTJ(38)\n",
      "VBG B-NP(37)\n",
      "CC B-ADJP(37)\n",
      "SYM I-ADJP(36)\n",
      "JJ B-ADVP(35)\n",
      "NNPS O(34)\n",
      "RP I-ADJP(29)\n",
      "FW I-VP(29)\n",
      "VBG O(26)\n",
      "JJ B-VP(26)\n",
      "RB B-VP(25)\n",
      "WRB B-NP(23)\n",
      "VB I-ADVP(22)\n",
      "FW I-ADJP(22)\n",
      "VBN I-ADVP(22)\n",
      "RBR O(22)\n",
      "RBS B-ADVP(22)\n",
      "JJ I-PRT(20)\n",
      "FW B-NP(19)\n",
      "WDT I-SBAR(19)\n",
      "JJ B-PP(18)\n",
      "MD I-NP(17)\n",
      "VBD I-ADJP(17)\n",
      "EX O(16)\n",
      "JJS I-PP(15)\n",
      "RBR B-ADVP(15)\n",
      "CC I-PRT(13)\n",
      ", I-ADVP(13)\n",
      "LS O(12)\n",
      "RB B-PP(12)\n",
      "$ B-ADJP(11)\n",
      "UH I-ADJP(11)\n",
      "RB B-ADJP(10)\n",
      "JJR I-VP(10)\n",
      "( I-VP(9)\n",
      "VB B-NP(8)\n",
      "JJR B-ADVP(8)\n",
      "'' I-ADJP(8)\n",
      ", I-INTJ(8)\n",
      "'' B-NP(8)\n",
      "RBR I-CONJP(7)\n",
      "PDT I-ADVP(7)\n",
      "VB I-ADJP(6)\n",
      "WP$ O(6)\n",
      "VBZ I-ADVP(6)\n",
      "JJR I-PP(6)\n",
      "RB|VBG I-NP(6)\n",
      "VB I-CONJP(6)\n",
      "UH O(5)\n",
      ", I-UCP(5)\n",
      ": I-LST(5)\n",
      "VBZ B-NP(5)\n",
      "WRB B-ADJP(5)\n",
      "JJ|RB I-ADVP(5)\n",
      "PRP$ I-ADJP(4)\n",
      ": B-NP(4)\n",
      "UH B-INTJ(4)\n",
      "RBS B-NP(4)\n",
      "VBG I-ADVP(4)\n",
      "JJS O(4)\n",
      "DT B-SBAR(4)\n",
      "RBS I-PP(4)\n",
      "PDT I-PP(3)\n",
      "WP O(3)\n",
      "$ O(3)\n",
      "VBP|TO I-VP(3)\n",
      "VBN B-ADVP(3)\n",
      "VBN I-SBAR(3)\n",
      "NN B-VP(3)\n",
      "RBR I-PRT(2)\n",
      "VBD I-ADVP(2)\n",
      ": I-ADJP(2)\n",
      "VBN B-ADJP(2)\n",
      "IN B-ADJP(2)\n",
      "WDT O(2)\n",
      "PRP$ I-INTJ(2)\n",
      "`` I-NP(2)\n",
      "CD|RB I-NP(2)\n",
      "RP B-ADVP(2)\n",
      ", B-ADJP(2)\n",
      "WP I-SBAR(2)\n",
      ": I-VP(2)\n",
      "POS I-ADJP(2)\n",
      "DT B-ADVP(2)\n",
      "RBR B-ADJP(1)\n",
      "'' I-VP(1)\n",
      "JJ I-LST(1)\n",
      "NNS I-UCP(1)\n",
      "JJ|VBG I-NP(1)\n",
      "CC B-ADVP(1)\n",
      "JJ I-SBAR(1)\n",
      "PDT I-ADJP(1)\n"
     ]
    }
   ],
   "source": [
    "# Path to your file Conell-2003 data file (Source: https://www.clips.uantwerpen.be/conll2003)\n",
    "file_path = \"tags.eng.raw\"\n",
    "\n",
    "# Create a dictionary to store the frequency of combinations\n",
    "combination_frequency = {}\n",
    "\n",
    "# Open and process the file\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        words = line.strip().split()  # Split the line into words\n",
    "        if len(words) == 2:  # Ensure there are two words on the line\n",
    "            word_a, word_b = words\n",
    "            combination = (word_a, word_b)\n",
    "            combination_frequency[combination] = combination_frequency.get(combination, 0) + 1\n",
    "\n",
    "# Sort the combinations by frequency in descending order\n",
    "sorted_combinations = sorted(combination_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the result in the desired format\n",
    "print(\"Frequency of Word_A and Word_B Combinations:\")\n",
    "for combination, frequency in sorted_combinations:\n",
    "    word_a, word_b = combination\n",
    "    print(f\"{word_a} {word_b}({frequency})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Word_A with associated Word_B and Frequencies:\n",
      "-X-: O(60343), \n",
      "NN: I-NP(2338500), I-INTJ(232), I-VP(3209), B-NP(7147), I-ADJP(1064), I-ADVP(2469), O(2432), I-UCP(77), B-VP(3), \n",
      ":: O(132474), I-NP(36844), I-ADVP(226), I-INTJ(442), I-ADJP(2), B-NP(4), I-LST(5), I-VP(2), \n",
      "NNP: I-NP(2132412), B-NP(23299), O(19476), I-VP(783), I-ADJP(253), I-INTJ(82), I-ADVP(51), B-VP(59), \n",
      "CD: I-NP(1077284), B-NP(23154), I-ADJP(441), I-ADVP(2582), I-VP(274), O(8857), \n",
      "IN: I-PP(1536758), I-SBAR(129441), I-NP(30138), I-ADVP(5949), B-PP(16357), B-NP(4504), I-CONJP(3291), O(1419), I-PRT(368), I-VP(1043), B-ADVP(86), I-ADJP(629), B-SBAR(1044), B-ADJP(2), \n",
      "RP: I-PRT(39009), I-ADVP(897), I-PP(562), I-ADJP(29), O(126), I-NP(58), B-ADVP(2), \n",
      "VBN: I-VP(304341), I-NP(27404), I-ADJP(5598), I-PP(6458), O(139), B-VP(250), B-PP(40), B-NP(62), I-ADVP(22), B-ADJP(2), B-ADVP(3), I-SBAR(3), \n",
      ".: O(653936), I-NP(4125), \n",
      ",: O(597461), I-NP(22004), B-VP(219), I-VP(685), B-NP(401), I-PP(78), I-ADJP(253), I-UCP(5), I-INTJ(8), I-ADVP(13), B-ADJP(2), \n",
      "VBD: I-VP(679521), I-NP(356), O(518), B-VP(2202), B-NP(61), I-ADVP(2), I-ADJP(17), \n",
      "(: I-NP(1283), O(94361), I-LST(1402), I-VP(9), \n",
      "): O(96887), I-NP(1071), \n",
      "DT: I-NP(1223799), O(2202), B-NP(44744), I-ADVP(979), I-SBAR(1057), I-ADJP(280), I-VP(122), I-PP(92), B-SBAR(4), B-ADVP(2), \n",
      "VBG: I-VP(195842), I-NP(30761), I-PP(14673), B-VP(369), I-ADJP(379), O(26), B-NP(37), I-ADVP(4), \n",
      "NNS: I-NP(983854), I-ADJP(100), I-VP(1032), B-NP(2445), I-ADVP(90), O(212), I-UCP(1), \n",
      "CC: I-NP(93836), O(240260), I-VP(6027), I-ADJP(2760), I-CONJP(617), I-ADVP(785), B-NP(377), I-PP(727), I-UCP(62), B-ADJP(37), I-PRT(13), B-ADVP(1), \n",
      "JJ: I-NP(933914), B-NP(15437), I-ADJP(111923), I-ADVP(3696), O(1441), I-VP(1498), I-PP(3729), I-UCP(60), I-INTJ(57), B-ADVP(35), B-PP(18), I-PRT(20), B-ADJP(53), B-VP(26), I-LST(1), I-SBAR(1), \n",
      "VBZ: I-VP(246893), I-NP(1066), B-VP(2278), O(641), I-ADVP(6), B-NP(5), \n",
      "RB: I-NP(46467), I-VP(96688), I-ADVP(191191), I-ADJP(25901), I-INTJ(387), O(12403), I-CONJP(7272), B-NP(1731), I-PRT(612), B-ADVP(1551), I-PP(3355), I-SBAR(1352), B-VP(25), B-SBAR(65), B-ADJP(10), B-PP(12), \n",
      "VBP: I-VP(144214), B-VP(1031), O(499), I-NP(82), \n",
      "PRP: I-NP(226643), B-NP(27967), O(326), \n",
      "NNPS: I-NP(49746), B-NP(69), O(34), \n",
      "WRB: I-ADVP(23443), B-ADVP(594), I-ADJP(238), I-NP(608), O(45), B-NP(23), B-ADJP(5), \n",
      "POS: B-NP(124031), I-NP(7739), I-VP(143), I-INTJ(45), I-ADJP(2), \n",
      "WP: I-NP(17710), B-NP(9543), O(3), I-SBAR(2), \n",
      "TO: I-VP(220679), I-PP(129163), B-PP(9093), B-VP(6086), I-NP(7367), O(198), I-ADVP(76), I-ADJP(100), \n",
      "VB: I-VP(418092), I-ADJP(6), O(171), B-NP(8), I-NP(1588), I-INTJ(351), B-VP(146), I-ADVP(22), I-CONJP(6), \n",
      "JJS: I-NP(26369), B-NP(121), I-ADJP(1115), I-ADVP(790), I-PP(15), I-VP(99), O(4), \n",
      "JJR: I-NP(38732), I-ADJP(10077), O(155), I-ADVP(1886), B-NP(696), B-ADVP(8), I-VP(10), I-PP(6), \n",
      "PRP$: I-NP(113147), B-NP(2851), I-ADJP(4), O(44), I-INTJ(2), \n",
      "MD: I-VP(147324), O(892), B-VP(1697), I-NP(17), \n",
      "\": O(231487), \n",
      "FW: I-NP(5756), O(451), B-NP(19), I-VP(29), I-INTJ(42), I-ADVP(113), I-ADJP(22), I-PP(63), \n",
      "RBS: I-ADJP(955), I-NP(3370), I-VP(196), I-ADVP(391), B-ADVP(22), B-NP(4), I-PP(4), \n",
      "SYM: O(86401), I-VP(3465), I-NP(535), B-NP(390), I-ADJP(36), \n",
      "RBR: I-ADVP(8707), B-NP(1213), I-ADJP(4813), I-NP(4861), I-VP(1002), I-PP(109), I-PRT(2), I-CONJP(7), O(22), B-ADVP(15), B-ADJP(1), \n",
      "$: I-NP(76565), B-ADJP(11), B-NP(3870), I-ADJP(691), O(3), \n",
      "WDT: B-NP(27208), I-NP(30135), I-SBAR(19), O(2), \n",
      "EX: I-NP(15809), B-NP(874), O(16), \n",
      "PDT: I-NP(2552), O(123), I-PP(3), B-NP(159), I-ADVP(7), I-ADJP(1), \n",
      "WP$: I-NP(1564), B-NP(735), O(6), \n",
      "LS: I-LST(1093), O(12), \n",
      "'': O(1984), I-NP(900), I-INTJ(38), I-ADJP(8), I-VP(1), B-NP(8), \n",
      "UH: I-INTJ(2666), O(5), I-NP(51), I-ADVP(39), I-ADJP(11), B-INTJ(4), \n",
      "NN|SYM: B-NP(254), I-NP(95), \n",
      "#: I-NP(60), \n",
      "VBP|TO: I-VP(3), \n",
      "RB|VBG: I-NP(6), \n",
      "``: I-NP(2), \n",
      "CD|RB: I-NP(2), \n",
      "JJ|RB: I-ADVP(5), \n",
      "JJ|VBG: I-NP(1), \n"
     ]
    }
   ],
   "source": [
    "# Path to your file Conell-2003 data file (Source: https://www.clips.uantwerpen.be/conll2003)\n",
    "file_path = \"tags.eng.raw\"\n",
    "\n",
    "# Create a dictionary to store the frequency of combinations\n",
    "combination_frequency = {}\n",
    "\n",
    "# Open and process the file\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        words = line.strip().split()  # Split the line into words\n",
    "        if len(words) == 2:  # Ensure there are two words on the line\n",
    "            word_a, word_b = words\n",
    "            combination = (word_a, word_b)\n",
    "            combination_frequency[combination] = combination_frequency.get(combination, 0) + 1\n",
    "\n",
    "# Create a dictionary to store unique Word_A with their associated Word_B combinations and frequencies\n",
    "word_a_dict = {}\n",
    "for (word_a, word_b), frequency in combination_frequency.items():\n",
    "    if word_a not in word_a_dict:\n",
    "        word_a_dict[word_a] = []\n",
    "    word_a_dict[word_a].append((word_b, frequency))\n",
    "\n",
    "# Display the result in the desired format\n",
    "print(\"Unique Word_A with associated Word_B and Frequencies:\")\n",
    "for word_a, combinations in word_a_dict.items():\n",
    "    print(f\"{word_a}: \", end=\"\")\n",
    "    for word_b, frequency in combinations:\n",
    "        print(f\"{word_b}({frequency}), \", end=\"\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of Word_A and Word_B Combinations:\n",
      "DT I-NP(1223799)\n",
      "DT B-NP(44744)\n",
      "DT O(2202)\n",
      "DT I-SBAR(1057)\n",
      "DT I-ADVP(979)\n",
      "DT I-ADJP(280)\n",
      "DT I-VP(122)\n",
      "DT I-PP(92)\n",
      "DT B-SBAR(4)\n",
      "DT B-ADVP(2)\n"
     ]
    }
   ],
   "source": [
    "# Test a sample tag from Conll-2003 and display the result in the desired format\n",
    "print(\"Frequency of Word_A and Word_B Combinations:\")\n",
    "test_word=\"DT\"\n",
    "for combination, frequency in sorted_combinations:\n",
    "    word_a,word_b =combination\n",
    "    if test_word == word_a:\n",
    "        print(f\"{word_a} {word_b}({frequency})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details of Tags(for conll-2003 dataset):\n",
    "<li>B/I-ADJP \tbegins/inside an adjective phrase.</li><li>\n",
    "B/I-ADVP \t\tbegins/inside an adverbial phrase.</li><li>\n",
    "B/I-CONJP \t    begins/inside a conjunctive phrase.</li><li>\n",
    "B/I-INTJ \t\tbegins/inside an interjection.</li><li>\n",
    "B/I-LST \t\tbegins/inside a list marker.</li><li>\n",
    "B/I-NP \t\t    begins/inside a noun phrase.</li><li>\n",
    "B/I-PP \t\t    begins/inside a prepositional phrase.</li><li>\n",
    "B/I-PRT \t\tbegins/inside a particle.</li><li>\n",
    "B/I-SBAR \t\tbegins/inside a subordinated clause.</li><li>\n",
    "B/I-UCP \t\tbegins/inside an unlike coordinated phrase.</li><li>\n",
    "B/I-VP \t\t    begins/inside a verb phrase.</li><li>\n",
    "O \t\t        is outside of any chunk.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rule creation of tags\n",
    "\n",
    "#flag_last_chunk=\"\"\n",
    "noun_POS=[\"NOUN\",\"PROPN\", \"DET\",\"PRON\"] \n",
    "noun_dep=[\"subj\",\"obj\",\"det\",\"nsubj\", \"poss\"]\n",
    "\n",
    "verb_POS=[\"VERB\",\"AUX\"]\n",
    "verb_dep=[\"aux\",\"ROOT\",\"dobj\",\"ccomp\",\"auxpass\"]\n",
    "\n",
    "adverb_POS=[\"ADV\"] \n",
    "adverb_dep=[\"advmod\"] \n",
    "\n",
    "prep_POS=[\"ADP\"]\n",
    "prep_dep=[\"prep\",\"prt\"]\n",
    "\n",
    "ADJ_POS=[\"ADJ\",\"JJ\"] \n",
    "ADJ_dep=[\"amod\",\"acomp\"]\n",
    "\n",
    "CConj_POS=[\"CCONJ\"] \n",
    "CConj_dep=[\"cc\"]\n",
    "\n",
    "Non_INF_POS=[\"VGNF\",\"VM\",\"VAUX\"] \n",
    "Non_INF_dep=verb_dep\n",
    "\n",
    "VGNN_Gerunds_POS=[\"VGNN\",\"VM\"] \n",
    "VGNN_Gerunds_dep=verb_dep\n",
    "\n",
    "INTJ_POS=[\"INTJ\"] \n",
    "INTJ_dep=[\"intj\"]\n",
    "\n",
    "others_POS=[\"PUNCT\",\"SYM\", \"NUM\",\"X\",\"SCONJ\"] #NO BIO TAGS: Puntuation, Symbols, Numbers, Other\n",
    "others_dep=[\"mark\"]\n",
    "\n",
    "part_POS=[\"PART\"]\n",
    "part_dep=[\"neg\",\"case\"]\n",
    "\n",
    "#Noun Rule\n",
    "#grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "def noun_chunker():\n",
    "    return 0\n",
    "\n",
    "#BIO Tagger\n",
    "def compare_last_chunk(last=\"\",current=\"\"):\n",
    "        if last.__contains__(current): \n",
    "            return \"I-\"+current \n",
    "        return \"B-\"+current\n",
    "\n",
    "def get_chunk_type(token,NER=False,previous_chunk=\"\"):\n",
    "    #Returns NP if there is NER found in the main.\n",
    "    if(NER):\n",
    "        return compare_last_chunk(previous_chunk,\"NP\")\n",
    "    \n",
    "    #Returns O for Puntuation, Symbols, Numbers, Other\n",
    "    elif token.pos_ in others_POS or token.dep_ in others_dep:\n",
    "        return \"O\" #Nothing to compare\n",
    "\n",
    "    #Returns NP \n",
    "    elif token.pos_ in noun_POS or token.dep_ in noun_dep:\n",
    "        return compare_last_chunk(previous_chunk,\"NP\")\n",
    "    \n",
    "    #Returns VB\n",
    "    elif token.pos_ in verb_POS or token.dep_ in verb_dep:\n",
    "        return compare_last_chunk(previous_chunk,\"VB\")\n",
    "\n",
    "    #Returns Adverb\n",
    "    elif token.pos_ in adverb_POS or token.dep_ in adverb_dep:\n",
    "        return compare_last_chunk(previous_chunk,\"ADV\")\n",
    "\n",
    "    #Returns preposition\n",
    "    elif token.pos_ in prep_POS or token.dep_ in prep_dep:\n",
    "        return compare_last_chunk(previous_chunk,\"ADP\")\n",
    "\n",
    "    #Returns Adjective\n",
    "    elif token.pos_ in ADJ_POS or token.dep_ in ADJ_dep:\n",
    "        return compare_last_chunk(previous_chunk,\"ADJ\")\n",
    "\n",
    "    #Returns CConj\n",
    "    elif token.pos_ in CConj_POS or token.dep_ in CConj_dep:\n",
    "        return compare_last_chunk(previous_chunk,\"CCONJ\")\n",
    "    \n",
    "\n",
    "    #Returns Non_INF_Gerunds\n",
    "    elif token.pos_ in Non_INF_POS or token.dep_ in Non_INF_dep:\n",
    "        return compare_last_chunk(previous_chunk,\"VGNF\")\n",
    "    \n",
    "    #Returns VGNN_Gerunds\n",
    "    elif token.pos_ in Non_INF_POS or token.dep_ in VGNN_Gerunds_dep:\n",
    "        return compare_last_chunk(previous_chunk,\"VGNN\")\n",
    "\n",
    "    #Returns VGNN_Gerunds\n",
    "    elif token.pos_ in INTJ_POS or token.dep_ in INTJ_dep:\n",
    "        return compare_last_chunk(previous_chunk,\"INTJ\")\n",
    "   \n",
    "    #parts\n",
    "    elif token.pos_ in part_POS or token.dep_ in part_dep:\n",
    "        return (\"I\"+previous_chunk[1:])\n",
    "\n",
    "    else:\n",
    "        return \"O\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert SpaCy NER results to CoNLL-2003 IOB format\n",
    "def spacy_to_conll2003_iob(text,chunking=\"false\"):\n",
    "    doc = nlp(text)\n",
    "    conll_lines = []\n",
    "    prev_ner_tag=\"\"\n",
    "    last_POS_DET=False\n",
    "    chunk=\"\"\n",
    "\n",
    "    for i, token in enumerate(doc):\n",
    "        word = token.text\n",
    "        \n",
    "        \n",
    "        if token.ent_type_==\"PERSON\" or token.ent_type_==\"PER\":\n",
    "            chunk=get_chunk_type(token,True,chunk)\n",
    "            ner_tag = token.ent_iob_ + \"-\" + \"PER\"\n",
    "        elif token.ent_type_==\"GPE\" or token.ent_type_==\"LOC\":\n",
    "            chunk=get_chunk_type(token,True,chunk)\n",
    "            ner_tag = token.ent_iob_ + \"-\" + \"LOC\" \n",
    "        elif token.ent_type_==\"ORG\":\n",
    "            chunk=get_chunk_type(token,True,chunk)    \n",
    "            ner_tag = token.ent_iob_ + \"-\" + \"ORG\"\n",
    "        #TODO: Ask if we should keep the other tags such title, etc. ?\n",
    "        elif token.ent_type_:\n",
    "            chunk=get_chunk_type(token,True,chunk)\n",
    "            ner_tag = token.ent_iob_ + \"-\" + \"OTH\"\n",
    "        else:\n",
    "            chunk=get_chunk_type(token,False,chunk)\n",
    "            ner_tag=\"O\"\n",
    "        \n",
    "        #Uncomment below line if want to output in BIO version#1 format instead of BIO version#2\n",
    "        '''\n",
    "        if i == 1 and ner_tag.startswith(\"B-\"):\n",
    "            ner_tag = \"I\" + ner_tag[1:]  # Replace \"B-\" with \"I-\" for the first entity\n",
    "        elif ner_tag.startswith(\"B-\") and prev_ner_tag.startswith(\"O\"):\n",
    "            ner_tag = \"I\" + ner_tag[1:]  # Replace \"B-\" with \"I-\" for subsequent entities after \"O\"\n",
    "        elif ner_tag.startswith(\"B-\") and (not (prev_ner_tag.__contains__(ner_tag[1:]))):\n",
    "            ner_tag = \"I\" + ner_tag[1:]  # Replace \"B-\" with \"I-\" for is previous Tag is different.\n",
    "        prev_ner_tag = ner_tag\n",
    "        '''\n",
    "\n",
    "        #Error correction: Skip writing SPACE to the Conll file as it will contain only three tags and would result in import error.\n",
    "        if not token.pos_==\"SPACE\":\n",
    "            #TODO: remove print in comment\n",
    "            # print(get_chunk_type(token))\n",
    "            #print({word} ,{token.pos_} ,{token.dep_+\":\"+chunk} ,{ner_tag})\n",
    "            if(token.pos_==\"DET\"):\n",
    "                last_POS_DET=True\n",
    "            \n",
    "            #TODO: both fake and real: select one?\n",
    "            if(chunking):\n",
    "                conll_lines.append(f\"{word} {token.pos_} {chunk} {ner_tag}\")\n",
    "            else:\n",
    "                conll_lines.append(f\"{word} {token.pos_} {token.dep_} {ner_tag}\")\n",
    "    return conll_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the content into sentences based on empty lines\n",
    "sentences = re.split(r\"\\n\\s*\\n\", content)\n",
    "\n",
    "# Process each sentence and convert to CoNLL-2003 IOB1 format\n",
    "conll_lines_list = []\n",
    "for sentence in sentences:\n",
    "    conll_lines = spacy_to_conll2003_iob(sentence)\n",
    "    conll_lines_list.extend(conll_lines)\n",
    "    #conll_lines_list.append(\"\")  # Add a blank line after each sentence\n",
    "\n",
    "# Join the lines with newlines\n",
    "conll_output = \"\\n\".join(conll_lines_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output file path in conll-2003 extension\n",
    "output_file = source_file[:-3]+\"conll2003\"\n",
    "\n",
    "#Write output file in conll-2003 format\n",
    "with open(output_file, \"w\") as output_file:\n",
    "    output_file.write(conll_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code of nltk library was used to further understand the sentence structues for chunking to create rules ( Source:https://www.nltk.org/book_1ed/ch07.html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.chunk import RegexpChunkParser\n",
    "from nltk.chunk.util import conlltags2tree, tree2conlltags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'little', 'yellow', 'dog', 'barked', 'at', 'the', 'cat']\n",
      "[('the', 'DT'), ('little', 'JJ'), ('yellow', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN')]\n",
      "(S\n",
      "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
      "  barked/VBD\n",
      "  at/IN\n",
      "  (NP the/DT cat/NN))\n",
      "                            S                                       \n",
      "     _______________________|______________________________          \n",
      "    |        |              NP                             NP       \n",
      "    |        |      ________|_________________        _____|____     \n",
      "barked/VBD at/IN the/DT little/JJ yellow/JJ dog/NN the/DT     cat/NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the little yellow dog barked at the cat\"\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "print(tokens)\n",
    "\n",
    "tag = nltk.pos_tag(tokens)\n",
    "print(tag)\n",
    "\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "chunk_parser = nltk.RegexpParser(grammar)\n",
    "chunks = chunk_parser.parse(tag)\n",
    "print(chunks)\n",
    "\n",
    "#output chunks\n",
    "chunks.pretty_print()\n",
    "#output chunks in the window\n",
    "#chunks.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
